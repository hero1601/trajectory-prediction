{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97693,"databundleVersionId":11656558,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":27.524611,"end_time":"2025-04-01T17:39:42.223757","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-01T17:39:14.699146","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-05-14T01:08:05.148222Z","iopub.execute_input":"2025-05-14T01:08:05.148428Z","iopub.status.idle":"2025-05-14T01:08:07.356126Z","shell.execute_reply.started":"2025-05-14T01:08:05.148408Z","shell.execute_reply":"2025-05-14T01:08:07.355124Z"},"papermill":{"duration":1.154057,"end_time":"2025-04-01T17:39:18.878059","exception":false,"start_time":"2025-04-01T17:39:17.724002","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/cse-251-b-2025/train.npz\n/kaggle/input/cse-251-b-2025/test_input.npz\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# download the dataset to your folder or use it on kaggle notebook directly\n\n# train_file = np.load('/your_folder/cse-251-b-2025/train.npz')\ntrain_file = np.load('/kaggle/input/cse-251-b-2025/train.npz')\n\ntrain_data = train_file['data']\nprint(\"train_data's shape\", train_data.shape)\n# test_file = np.load('/your_folder/test_input.npz')\ntest_file = np.load('/kaggle/input/cse-251-b-2025/test_input.npz')\n\ntest_data = test_file['data']\nprint(\"test_data's shape\", test_data.shape)\n","metadata":{"execution":{"iopub.status.busy":"2025-05-14T01:08:07.357863Z","iopub.execute_input":"2025-05-14T01:08:07.358299Z","iopub.status.idle":"2025-05-14T01:08:27.882787Z","shell.execute_reply.started":"2025-05-14T01:08:07.358272Z","shell.execute_reply":"2025-05-14T01:08:27.882060Z"},"papermill":{"duration":22.084222,"end_time":"2025-04-01T17:39:40.970631","exception":false,"start_time":"2025-04-01T17:39:18.886409","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"train_data's shape (10000, 50, 110, 6)\ntest_data's shape (2100, 50, 50, 6)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Split x and y for train data.\n\ntrain_x, train_y = train_data[..., :50, :], train_data[:, 0, 50:, :2]\n\nprint(train_x.shape, train_y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:08:27.884027Z","iopub.execute_input":"2025-05-14T01:08:27.884335Z","iopub.status.idle":"2025-05-14T01:08:27.888947Z","shell.execute_reply.started":"2025-05-14T01:08:27.884312Z","shell.execute_reply":"2025-05-14T01:08:27.888303Z"}},"outputs":[{"name":"stdout","text":"(10000, 50, 50, 6) (10000, 60, 2)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm\n\nclass TrajectoryModel(nn.Module):\n    def __init__(self, input_features, output_features):\n        super(TrajectoryModel, self).__init__()\n        \n        # Define the layers\n        # self.conv1 = nn.Conv2d(6,32,3,padding=1)\n        # self.conv2 = nn.Conv2d(32,64,3,padding=1)\n        # self.conv3 = nn.Conv2d(64,128,3,padding=1)\n\n        # self.dropout = nn.Dropout(0.3)\n\n\n        # self.pool = nn.MaxPool2d(2,2)\n        self.relu = nn.ReLU()\n\n        self.fc1 = nn.Linear(input_features, 2048)\n        self.fc2 = nn.Linear(2048 , output_features)\n        # self.fc3 = nn.Linear(512 , output_features)\n    \n    def forward(self, x):\n        # x = self.relu(self.conv1(x))\n        # x = self.pool(self.relu(self.conv2(x)))\n        # x = self.pool(self.relu(self.conv3(x)))\n        x = x.view(x.size(0), -1)\n        x = self.relu(self.fc1(x))\n        # x = self.relu(self.fc2(x))\n        x = self.fc2(x)\n        return x.resize(x.size(0),60,2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:09:32.586862Z","iopub.execute_input":"2025-05-14T01:09:32.587274Z","iopub.status.idle":"2025-05-14T01:09:32.595306Z","shell.execute_reply.started":"2025-05-14T01:09:32.587243Z","shell.execute_reply":"2025-05-14T01:09:32.594322Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class LSTM(nn.Module):\n    def __init__(self, input_size = 6, output_features = 120):\n        super(LSTM, self).__init__()\n        \n        self.lstm = nn.LSTM(input_size , 256 , batch_first = True)\n        self.fc1 = nn.Linear(256 , output_features)\n    \n    def forward(self, x):\n        batch , num_agents , time_steps, features = x.size()\n        x = x.view(batch*num_agents,time_steps,features)\n        output,(h_n,c_n) = self.lstm(x)\n        x = self.fc1(output[:,-1,:])\n        # print(x.shape)\n        x = x[:batch,:]\n        return x.view(-1,60,2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:09:32.596545Z","iopub.execute_input":"2025-05-14T01:09:32.596834Z","iopub.status.idle":"2025-05-14T01:09:32.624967Z","shell.execute_reply.started":"2025-05-14T01:09:32.596809Z","shell.execute_reply":"2025-05-14T01:09:32.624157Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class TrajectoryRNN(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, num_steps, num_agents):\n        super(TrajectoryRNN, self).__init__()\n\n        self.input_dim  =input_dim\n        self.hidden_dim = hidden_dim\n        self.num_steps = num_steps\n        self.num_agents = num_agents\n        \n        # LSTM layer for trajectory prediction\n        self.lstm = nn.LSTM(input_dim * num_agents, hidden_dim, batch_first=True)\n        \n        # Fully connected layer to output the predicted trajectory (x, y)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n    \n    def forward(self, x):\n        # x: shape [batch_size, num_agents, num_time_steps, input_dim]\n        \n        batch_size = x.size(0)\n        \n        # Reshape input to have shape [batch_size, num_time_steps, num_agents * input_dim]\n        x = x.view(batch_size, x.size(2), self.num_agents * x.size(3))  # shape: [batch_size, num_time_steps, 50 * 6]\n        \n        # Initialize hidden and cell states for LSTM\n        h0 = torch.zeros(1, batch_size, self.hidden_dim).to(x.device)  # hidden state\n        c0 = torch.zeros(1, batch_size, self.hidden_dim).to(x.device)  # cell state\n    \n        # Pass through the LSTM\n        lstm_out, (hn, cn) = self.lstm(x, (h0, c0))\n        \n        predictions = []\n    \n        for t in range(self.num_steps):\n            # Take the last output from LSTM (last time step)\n            lstm_out_last = lstm_out[:, -1, :]\n            \n            # Get the predicted x, y for all agents (output_dim = 2 * num_agents)\n            output = self.fc(lstm_out_last)  # shape: [batch_size, num_agents * 2]\n            \n            # Store all predictions but only return for agent 0\n            predictions.append(output[:, :2].unsqueeze(1))  # Get only the first 2 values for agent 0 (x, y)\n            \n            # Shift the inputs (for teacher forcing) - not necessary for all models\n            expanded_output = output.unsqueeze(2).expand(-1, -1, self.num_agents * self.input_dim)\n            \n            # Concatenate along the time dimension\n            x = torch.cat((x[:, 1:, :], expanded_output), dim=1)  # shape: [batch_size, num_time_steps, 50 * 6]\n        \n        # Stack all the predictions into a tensor\n        return torch.cat(predictions, dim=1)  # shape: [batch_size, num_steps, 2]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:09:32.627007Z","iopub.execute_input":"2025-05-14T01:09:32.627284Z","iopub.status.idle":"2025-05-14T01:09:32.643057Z","shell.execute_reply.started":"2025-05-14T01:09:32.627260Z","shell.execute_reply":"2025-05-14T01:09:32.642315Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Calculate the total number of features after flattening\ninput_features = 50 * 50 * 6  # = 5000\noutput_features = 60 * 2\n\n\n# Create the model\nmodel = TrajectoryModel(input_features, output_features)\n# model = LSTM()\n# model = TrajectoryRNN(input_dim=6, hidden_dim=128, output_dim=2, num_steps=60,num_agents = 50)\n\n# Define loss function and optimizer\ncriterion = nn.MSELoss()  # For regression task\n\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:10:27.548453Z","iopub.execute_input":"2025-05-14T01:10:27.548737Z","iopub.status.idle":"2025-05-14T01:10:27.835515Z","shell.execute_reply.started":"2025-05-14T01:10:27.548715Z","shell.execute_reply":"2025-05-14T01:10:27.834673Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:10:27.836818Z","iopub.execute_input":"2025-05-14T01:10:27.837124Z","iopub.status.idle":"2025-05-14T01:10:27.841232Z","shell.execute_reply.started":"2025-05-14T01:10:27.837099Z","shell.execute_reply":"2025-05-14T01:10:27.840249Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"\n# Example of how to prepare data and train the model\n\ndef train_model(model, x_train, y_train, batch_size=64, epochs=10):\n    \n    \n    X_train_tensor = torch.FloatTensor(x_train).to(device) \n    y_train_tensor = torch.FloatTensor(y_train).to(device)   \n    # DataLoader\n    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    \n    # Model to device\n    model = model.to(device)\n    \n    # Training loop\n    for epoch in range(epochs):\n        model.train()\n        running_loss = 0.0\n        \n        for batch_X, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(batch_X)\n            # print(outputs.shape)\n            # print(batch_y.shape)\n            \n            # Compute loss\n            loss = criterion(outputs, batch_y)\n            \n            # Backward and optimize\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        avg_loss = running_loss / len(train_loader)\n        print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n    \n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:10:27.842981Z","iopub.execute_input":"2025-05-14T01:10:27.843226Z","iopub.status.idle":"2025-05-14T01:10:27.861733Z","shell.execute_reply.started":"2025-05-14T01:10:27.843204Z","shell.execute_reply":"2025-05-14T01:10:27.860946Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model = train_model(model, train_x, train_y, 32, 150)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:15:56.773450Z","iopub.execute_input":"2025-05-14T01:15:56.773811Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/150: 100%|██████████| 313/313 [00:03<00:00, 84.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 - Loss: 1352.6529\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/150: 100%|██████████| 313/313 [00:03<00:00, 85.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 - Loss: 2624.8956\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/150: 100%|██████████| 313/313 [00:03<00:00, 85.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 - Loss: 2090.8836\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/150: 100%|██████████| 313/313 [00:03<00:00, 85.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 - Loss: 981.9872\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/150: 100%|██████████| 313/313 [00:03<00:00, 85.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 - Loss: 624.1160\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/150: 100%|██████████| 313/313 [00:03<00:00, 85.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 - Loss: 586.0497\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/150: 100%|██████████| 313/313 [00:03<00:00, 84.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 - Loss: 1333.4887\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/150: 100%|██████████| 313/313 [00:03<00:00, 85.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 - Loss: 596.1072\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/150: 100%|██████████| 313/313 [00:03<00:00, 85.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 - Loss: 576.7310\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/150: 100%|██████████| 313/313 [00:03<00:00, 85.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 - Loss: 633.4853\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/150: 100%|██████████| 313/313 [00:03<00:00, 85.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 - Loss: 2814.5843\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/150: 100%|██████████| 313/313 [00:03<00:00, 85.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 - Loss: 1325.2786\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/150: 100%|██████████| 313/313 [00:03<00:00, 85.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 - Loss: 735.6374\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/150: 100%|██████████| 313/313 [00:03<00:00, 85.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 - Loss: 661.9490\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/150: 100%|██████████| 313/313 [00:03<00:00, 85.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 - Loss: 768.8479\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/150: 100%|██████████| 313/313 [00:03<00:00, 84.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 - Loss: 887.4638\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/150: 100%|██████████| 313/313 [00:03<00:00, 85.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 - Loss: 1527.1868\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/150: 100%|██████████| 313/313 [00:03<00:00, 85.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 - Loss: 1811.3284\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/150: 100%|██████████| 313/313 [00:03<00:00, 85.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 - Loss: 924.7458\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/150: 100%|██████████| 313/313 [00:03<00:00, 85.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 - Loss: 1186.7194\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/150: 100%|██████████| 313/313 [00:03<00:00, 85.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 - Loss: 939.0512\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/150: 100%|██████████| 313/313 [00:03<00:00, 85.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 - Loss: 668.3959\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/150: 100%|██████████| 313/313 [00:03<00:00, 85.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 - Loss: 597.0264\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/150: 100%|██████████| 313/313 [00:03<00:00, 85.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 - Loss: 1198.2673\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/150: 100%|██████████| 313/313 [00:03<00:00, 84.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 - Loss: 949.1153\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/150: 100%|██████████| 313/313 [00:03<00:00, 85.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 - Loss: 798.3432\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/150: 100%|██████████| 313/313 [00:03<00:00, 85.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 - Loss: 746.5012\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/150: 100%|██████████| 313/313 [00:03<00:00, 85.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 - Loss: 1050.4873\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/150: 100%|██████████| 313/313 [00:03<00:00, 85.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 - Loss: 825.7768\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/150: 100%|██████████| 313/313 [00:03<00:00, 85.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 - Loss: 1239.5740\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/150: 100%|██████████| 313/313 [00:03<00:00, 85.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31 - Loss: 879.4534\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/150: 100%|██████████| 313/313 [00:03<00:00, 85.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32 - Loss: 875.0761\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/150: 100%|██████████| 313/313 [00:03<00:00, 84.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33 - Loss: 942.0719\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/150: 100%|██████████| 313/313 [00:03<00:00, 85.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34 - Loss: 1083.6075\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/150: 100%|██████████| 313/313 [00:03<00:00, 85.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35 - Loss: 942.7614\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/150: 100%|██████████| 313/313 [00:03<00:00, 85.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36 - Loss: 772.4368\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/150: 100%|██████████| 313/313 [00:03<00:00, 85.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37 - Loss: 783.1315\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/150: 100%|██████████| 313/313 [00:03<00:00, 85.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38 - Loss: 957.9916\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/150: 100%|██████████| 313/313 [00:03<00:00, 85.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39 - Loss: 637.2121\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/150: 100%|██████████| 313/313 [00:03<00:00, 85.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40 - Loss: 912.3319\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/150: 100%|██████████| 313/313 [00:03<00:00, 84.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41 - Loss: 741.3538\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/150: 100%|██████████| 313/313 [00:03<00:00, 84.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42 - Loss: 797.7632\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/150: 100%|██████████| 313/313 [00:03<00:00, 85.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43 - Loss: 711.9319\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/150:  86%|████████▋ | 270/313 [00:03<00:00, 85.13it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\ndef predict(X_test):\n    model.eval()\n    with torch.no_grad():\n        X_test_tensor = torch.FloatTensor(X_test).to(device) \n        predictions = model(X_test_tensor).to(device)\n    \n    # Move predictions to CPU before converting to NumPy\n    return predictions.cpu().numpy()\n\n# Save model\ndef save_model(path=\"mlp_model.pth\"):\n    torch.save(model.state_dict(), path)\n    print(f\"Model saved to {path}\")\n\n# Load model\ndef load_model(path=\"mlp_model.pth\"):\n    loaded_model = TrajectoryModel()\n    loaded_model.load_state_dict(torch.load(path))\n    loaded_model.eval()\n    return loaded_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:15:22.556952Z","iopub.execute_input":"2025-05-14T01:15:22.557188Z","iopub.status.idle":"2025-05-14T01:15:22.562026Z","shell.execute_reply.started":"2025-05-14T01:15:22.557168Z","shell.execute_reply":"2025-05-14T01:15:22.561192Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Get predictions from the model\npred_y = predict(test_data)\n\n# Move pred_y to CPU if it's on the GPU\n# pred_y = pred_y.detach().cpu()\n\n# Now reshape pred_y after it's on the CPU\npred_output = pred_y.reshape(-1, 2)  # Convert to NumPy after moving to CPU\n\n# Create the DataFrame\noutput_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n\n# Adding a necessary step to match index of your prediction to that of the solution key\noutput_df.index.name = 'index'\n\n# Save to CSV\noutput_df.to_csv('mlp_baseline.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T01:15:22.562711Z","iopub.execute_input":"2025-05-14T01:15:22.562986Z","iopub.status.idle":"2025-05-14T01:15:23.029668Z","shell.execute_reply.started":"2025-05-14T01:15:22.562966Z","shell.execute_reply":"2025-05-14T01:15:23.028958Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":" # Now you can submit to the leaderboard!","metadata":{"papermill":{"duration":0.003051,"end_time":"2025-04-01T17:39:41.596387","exception":false,"start_time":"2025-04-01T17:39:41.593336","status":"completed"},"tags":[]}}]}