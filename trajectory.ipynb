{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE251B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You need to describe in your own words what the dataset is about, and use mathematical language and formulate your prediction task on the submitted PDF file for Question 1 Problem A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are loading the dataset from the local directory. And answer Question 1 Problem B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_npz = np.load('/kaggle/input/cse-251-b-2025/train.npz')\n",
    "train_data = train_npz['data']\n",
    "test_npz  = np.load('/kaggle/input/cse-251-b-2025/test_input.npz')\n",
    "test_data  = test_npz['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_data.shape, test_data.shape)\n",
    "\n",
    "# Split once for later use\n",
    "X_train = train_data[..., :50, :]\n",
    "Y_train = train_data[:, 0, 50:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_heatmap(data, title=None, bins=5):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    x_max = data[..., 0].max()\n",
    "    x_min = data[..., 0].min()\n",
    "    y_max = data[..., 1].max()\n",
    "    y_min = data[..., 1].min()\n",
    "\n",
    "    plt.hist2d(data[:, 0], data[:, 1], bins=bins, cmap='hot')\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(label='Density')\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "xy_in = train_data[:, :, :50, :2].reshape(-1, 2)\n",
    "# only find the x, y != 0\n",
    "xy_in_not_0 = xy_in[(xy_in[:, 0] != 0) & (xy_in[:, 1] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_heatmap(xy_in, title='Heatmap of XY In', bins=5)\n",
    "plot_heatmap(xy_in_not_0, title='Heatmap of XY In (non-zero)', bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_heatmap(xy_in, title='Heatmap of XY In', bins=50)\n",
    "plot_heatmap(xy_in_not_0, title='Heatmap of XY In (non-zero)', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to play around with dataset for training and testing, make exploratory analysis on the dataset for bonus points(up to 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setting up the Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TrajectoryDatasetTrain(Dataset):\n",
    "    def __init__(self, data, scale=10.0, augment=True):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Training data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        augment: Whether to apply data augmentation (only for training)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx]\n",
    "        # Getting 50 historical timestamps and 60 future timestamps\n",
    "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
    "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
    "        \n",
    "        # Data augmentation(only for training)\n",
    "        if self.augment:\n",
    "            if np.random.rand() < 0.5:\n",
    "                theta = np.random.uniform(-np.pi, np.pi)\n",
    "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
    "                # Rotate the historical trajectory and future trajectory\n",
    "                hist[..., :2] = hist[..., :2] @ R\n",
    "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
    "                future = future @ R\n",
    "            if np.random.rand() < 0.5:\n",
    "                hist[..., 0] *= -1\n",
    "                hist[..., 2] *= -1\n",
    "                future[:, 0] *= -1\n",
    "\n",
    "        # Use the last timeframe of the historical trajectory as the origin\n",
    "        origin = hist[0, 49, :2].copy()  # (2,)\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        future = future - origin\n",
    "\n",
    "        # Normalize the historical trajectory and future trajectory\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "        future = future / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            y=future.type(torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "        return data_item\n",
    "    \n",
    "\n",
    "class TrajectoryDatasetTest(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Testing data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Testing data only contains historical trajectory\n",
    "        scene = self.data[idx]  # (50, 50, 6)\n",
    "        hist = scene.copy()\n",
    "        \n",
    "        origin = hist[0, 49, :2].copy()\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "        return data_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer Question related to Your Computational Platform and GPU for Question 2 Problem A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(251)\n",
    "np.random.seed(42)\n",
    "\n",
    "scale = 7.0\n",
    "\n",
    "N = len(train_data)\n",
    "val_size = int(0.2 * N)\n",
    "train_size = N - val_size\n",
    "\n",
    "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
    "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "\n",
    "# Set device for training speedup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Model for Question 2 Problem B (Include your model architecture pictures and also can use some mathmatical equations to explain your model in your report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim=50 * 50 * 2, output_dim=60 * 2):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x[..., :2] # (batch*50, 50, 2)\n",
    "        x = x.reshape(-1, 50 * 50 * 2) # (batch, 5000)\n",
    "        x = self.linear(x)\n",
    "        return x.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(256, output_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x = x[:, :, :, :2] # (batch, 50, 50, 2)\n",
    "        x = x.reshape(-1, 50 * 50 * 6)\n",
    "        x = self.mlp(x)\n",
    "        return x.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Model will be covered during Week 6 Lecture (If you don't understand it for now, don't worry, we will cover it in the lecture, or you can ask in the office hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=6, hidden_dim=128, output_dim=60 * 2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        x = x[:, 0, :, :] # Only Consider ego agent index 0\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Optimizer and Hyperparameters for Question 2 Problem A (Try to use different optimizers and hyperparameters for your model and see how it affects the performance of your model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model = LinearRegressionModel().to(device)\n",
    "# model = MLP(50 * 50 * 6, 60 * 2).to(device)\n",
    "model = LSTM().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
    "early_stopping_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "no_improvement = 0\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Simple Linear Regression Model for Question 2B and Visualize the validation loss(MAE) (Hint: You should adapt the code for training loss and try to draw graphs as specified in the project description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm.tqdm(range(100), desc=\"Epoch\", unit=\"epoch\"):\n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch)\n",
    "        y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "        loss = criterion(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_mae = 0\n",
    "    val_mse = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "            val_loss += criterion(pred, y).item()\n",
    "\n",
    "            # show MAE and MSE with unnormalized data\n",
    "            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "            y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "            val_mae += nn.L1Loss()(pred, y).item()\n",
    "            val_mse += nn.MSELoss()(pred, y).item()\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_mae /= len(val_dataloader)\n",
    "    val_mse /= len(val_dataloader)\n",
    "    # scheduler.step()\n",
    "    # scheduler.step(val_loss)\n",
    "    \n",
    "    tqdm.tqdm.write(f\"Epoch {epoch:03d} | Learning rate {optimizer.param_groups[0]['lr']:.6f} | train normalized MSE {train_loss:8.4f} | val normalized MSE {val_loss:8.4f}, | val MAE {val_mae:8.4f} | val MSE {val_mse:8.4f}\")\n",
    "    if val_loss < best_val_loss - 1e-3:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement >= early_stopping_patience:\n",
    "            print(\"Early stop!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly sample validation dataset and Visualize the ground truth and your predictions on a 2D plane for Question 3 Problem A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def plot_trajectory(ax, pred, gt, title=None):\n",
    "    ax.cla()\n",
    "    # Plot the predicted future trajectory\n",
    "    ax.plot(pred[0,:60,0], pred[0,:60,1], color='red', label='Predicted Future Trajectory')\n",
    "    \n",
    "    # Plot the ground truth future trajectory\n",
    "    ax.plot(gt[0,:60,0], gt[0,:60,1], color='blue', label='Ground Truth Future Trajectory')\n",
    "    \n",
    "    # Optionally set axis limits, labels, and title.\n",
    "    x_max = max(pred[..., 0].max(), gt[..., 0].max())\n",
    "    x_min = min(pred[..., 0].min(), gt[..., 0].min())\n",
    "    y_max = max(pred[..., 1].max(), gt[..., 1].max())\n",
    "    y_min = min(pred[..., 1].min(), gt[..., 1].min())\n",
    "    \n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# randomly select 4 samples from the validation set\n",
    "random_indices = random.sample(range(len(val_dataset)), 4)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
    "axes = axes.flatten()  # Flatten the array to iterate single axes objects\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    batch = val_dataset[idx]\n",
    "    batch = batch.to(device)\n",
    "    pred = model(batch)\n",
    "    gt = torch.stack(torch.split(batch.y, 60, dim=0), dim=0)\n",
    "\n",
    "    pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "    gt = torch.stack(torch.split(batch.y, 60, dim=0), dim=0) * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    gt = gt.detach().cpu().numpy()\n",
    "\n",
    "    # Plot the trajectory using the i-th axis\n",
    "    plot_trajectory(axes[i], pred, gt, title=f\"Sample {idx}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output your predictions of the best model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False,\n",
    "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
    "\n",
    "best_model = torch.load(\"best_model.pt\")\n",
    "# model = LinearRegressionModel().to(device)\n",
    "# model = MLP(50 * 50 * 6, 60 * 2).to(device)\n",
    "# model = LSTM().to(device)\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        pred_norm = model(batch)\n",
    "        \n",
    "        # Reshape the prediction to (N, 60, 2)\n",
    "        pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
    "        pred_list.append(pred.cpu().numpy())\n",
    "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
    "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "output_df.index.name = 'index'\n",
    "output_df.to_csv('submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Summarize your experiments and results in table and figures in the submitted PDF file for Question 3 Problem A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze the results, identify the issues and plan for the improvement in the submitted PDF file for Question 3 Problem B"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11656558,
     "isSourceIdPinned": false,
     "sourceId": 97693,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
